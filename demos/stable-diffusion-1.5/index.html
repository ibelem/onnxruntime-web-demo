<html>
<!--
    Usage:
        index.html // defaults to WebNN GPU
        index.html?provider=webnn&device=gpu
        index.html?provider=webnn&device=cpu
        index.html?provider=wasm

        provider = wasm | webnn | webgpu | webgl
        device = cpu | gpu | npu // applicable to WebNN
-->

<head>
    <meta charset='utf-8'>
    <title>ONNX Runtime Web - Stable Diffusion 1.5</title>
    <link rel="apple-touch-icon" sizes="180x180" href="./static/favicon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="./static/favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="./static/favicon/favicon-16x16.png">
    <link rel="stylesheet" href="./static/main.css">
</head>

<body>
    <div class="grid-2 p1 v1">
        <h1 class="title">
            <div id="back">
                <a href="../../">
                    <svg xmlns="http://www.w3.org/2000/svg" height="24" viewBox="0 -960 960 960" width="24">
                        <path d="m313-440 224 224-57 56-320-320 320-320 57 56-224 224h487v80H313Z" />
                    </svg>
                </a>
            </div>
            <svg version="1.1" id="ort-logo" x="0px" y="0px" viewBox="0 0 217 74"
                style="enable-background:new 0 0 217 74;" xml:space="preserve">
                <style type="text/css">
                    .st0 {
                        fill: #333333;
                    }

                    .st1 {
                        fill: #FFFFFF;
                    }

                    .st2 {
                        fill: #D1D1D1;
                    }

                    .st3 {
                        fill: #B2B2B2;
                    }
                </style>
                <g>
                    <g>
                        <g>
                            <path class="st0" d="M95.92,26.59V12.43c0-6.83,5.14-9.38,11.88-9.38c6.68,0,11.94,2.55,11.94,9.38v14.16
                  c0,6.83-5.26,9.38-11.94,9.38C101.07,35.97,95.92,33.43,95.92,26.59z M116.79,12.43c0-4.96-3.37-7.24-8.99-7.24
                  c-5.62,0-8.93,2.28-8.93,7.24v14.16c0,4.96,3.31,7.24,8.93,7.24c5.62,0,8.99-2.28,8.99-7.24V12.43z" />
                            <path class="st0"
                                d="M149.02,34.05L131.63,8.32v26.4c0,0.67-0.71,0.98-1.48,0.98c-0.71,0-1.48-0.31-1.48-0.98V3.99
                  c0-0.71,0.71-0.94,1.48-0.94c1.06,0,1.89,1.07,2.42,1.83l17.09,25.51V3.99c0-0.67,0.77-0.94,1.48-0.94
                  c0.77,0,1.48,0.27,1.48,0.94v30.73c0,0.67-0.71,0.98-1.48,0.98C150.26,35.71,149.55,34.81,149.02,34.05z" />
                            <path class="st0"
                                d="M182.3,34.05L164.92,8.32v26.4c0,0.67-0.71,0.98-1.48,0.98c-0.71,0-1.48-0.31-1.48-0.98V3.99
                  c0-0.71,0.71-0.94,1.48-0.94c1.06,0,1.89,1.07,2.42,1.83l17.09,25.51V3.99c0-0.67,0.77-0.94,1.48-0.94
                  c0.77,0,1.48,0.27,1.48,0.94v30.73c0,0.67-0.71,0.98-1.48,0.98C183.54,35.71,182.83,34.81,182.3,34.05z" />
                            <path class="st0" d="M204.3,21.46l-8.75,12.78c-0.41,0.63-0.89,1.52-1.77,1.52c-0.77,0-1.66-0.49-1.66-1.12
                  c0-0.18,0.12-0.36,0.24-0.58l10.17-14.7l-9.99-14.56c-0.24-0.31-0.36-0.58-0.36-0.85c0-0.58,0.71-0.94,1.66-0.94
                  c0.83,0,1.42,0.85,1.89,1.56l8.57,12.64l8.63-12.64c0.47-0.62,1.01-1.56,1.89-1.56c0.95,0,1.66,0.36,1.66,0.94
                  c0,0.27-0.12,0.54-0.36,0.85l-10.05,14.56l10.23,14.7c0.12,0.22,0.24,0.4,0.24,0.58c0,0.63-0.83,1.12-1.66,1.12
                  c-0.89,0-1.36-0.89-1.77-1.52L204.3,21.46z" />
                        </g>
                        <g>
                            <path class="st0" d="M109.47,53.62c0-2.28-0.65-3.95-1.94-4.97c-1.29-1.02-2.99-1.53-5.06-1.53l-5.65,0
                  c-0.43,0.05-0.64,0.26-0.64,0.62v23.54c0,0.43,0.22,0.65,0.65,0.65s0.65-0.22,0.65-0.65V60.15h4.94l5.4,10.53l0.01,0.02h0.01
                  c0.01,0.01,0.05,0.06,0.14,0.24l0.14,0.38c0.05,0.07,0.11,0.16,0.19,0.27c0.08,0.12,0.17,0.2,0.25,0.25
                  c0.08,0.05,0.18,0.07,0.27,0.07c0.19,0,0.35-0.06,0.47-0.18c0.12-0.12,0.18-0.28,0.18-0.47c0-0.12-0.04-0.25-0.11-0.39
                  l-5.55-10.8C107.57,59.61,109.47,57.44,109.47,53.62z M108.17,53.62c0,1.78-0.51,3.11-1.52,3.96c-1.01,0.85-2.42,1.28-4.18,1.28
                  h-5V48.42h5c1.76,0,3.17,0.42,4.18,1.26C107.66,50.51,108.17,51.83,108.17,53.62z" />
                            <path class="st0" d="M127.25,47.12c-0.43,0-0.65,0.21-0.65,0.62v17.38c0,1.9-0.47,3.34-1.39,4.28c-0.92,0.95-2.26,1.42-3.98,1.42
                  c-1.72,0-3.05-0.48-3.96-1.42c-0.91-0.95-1.38-2.39-1.38-4.28V47.73c0-0.41-0.22-0.62-0.65-0.62s-0.65,0.21-0.65,0.62v17.38
                  c0,2.41,0.61,4.2,1.8,5.32c1.2,1.12,2.82,1.68,4.83,1.68s3.64-0.57,4.85-1.68c1.21-1.12,1.82-2.91,1.82-5.32V47.73
                  C127.9,47.32,127.68,47.12,127.25,47.12z" />
                            <path class="st0"
                                d="M147.3,47.12c-0.43,0-0.65,0.21-0.65,0.62V68.7l-10.27-20.34c-0.46-0.83-0.82-1.24-1.08-1.24
                  c-0.43,0-0.65,0.21-0.65,0.62v23.54c0,0.43,0.22,0.65,0.65,0.65c0.43,0,0.65-0.22,0.65-0.65V50.3l10.34,20.38
                  c0.42,0.83,0.75,1.24,1.02,1.24c0.43,0,0.65-0.22,0.65-0.65V47.73C147.95,47.32,147.74,47.12,147.3,47.12z" />
                            <path class="st0" d="M166.38,47.12h-13.22c-0.19,0-0.35,0.07-0.47,0.2c-0.12,0.13-0.18,0.28-0.18,0.45
                  c0,0.17,0.06,0.32,0.18,0.45c0.12,0.13,0.28,0.2,0.47,0.2h5.98v22.85c0,0.43,0.22,0.65,0.65,0.65c0.43,0,0.65-0.22,0.65-0.65
                  V48.42h5.95c0.43,0,0.65-0.23,0.65-0.68C167.03,47.32,166.81,47.12,166.38,47.12z" />
                            <path class="st0" d="M172.23,47.12c-0.43,0-0.65,0.21-0.65,0.62v23.54c0,0.43,0.22,0.65,0.65,0.65c0.43,0,0.65-0.22,0.65-0.65
                  V47.73C172.88,47.32,172.66,47.12,172.23,47.12z" />
                            <path class="st0" d="M195.66,47.12c-0.27,0-0.62,0.41-1.08,1.24l-6.56,12.85l-6.53-12.85c-0.46-0.83-0.82-1.24-1.08-1.24
                  c-0.43,0-0.65,0.21-0.65,0.62v23.54c0,0.43,0.22,0.65,0.65,0.65c0.43,0,0.65-0.22,0.65-0.65V50.3l6.28,12.16
                  c0.21,0.45,0.43,0.67,0.68,0.67c0.22,0,0.44-0.22,0.68-0.66l6.31-12.16v20.97c0,0.43,0.22,0.65,0.65,0.65
                  c0.43,0,0.65-0.22,0.65-0.65V47.73C196.31,47.32,196.09,47.12,195.66,47.12z" />
                            <path class="st0" d="M215.89,70.62H204.5V60.15h5.37c0.41,0,0.62-0.21,0.62-0.62c0-0.45-0.21-0.68-0.62-0.68h-5.37V48.42h11.39
                  c0.41,0,0.62-0.23,0.62-0.68c0-0.4-0.21-0.62-0.62-0.62h-12.04c-0.43,0-0.65,0.22-0.65,0.65v23.5c0,0.43,0.22,0.65,0.65,0.65
                  h12.04c0.41,0,0.62-0.21,0.62-0.62C216.5,70.85,216.29,70.62,215.89,70.62z" />
                        </g>
                    </g>
                    <g>
                        <g>
                            <polygon class="st1" points="58.11,20.09 39.33,41.08 39.33,1.31 			" />
                            <polyline class="st2" points="58.11,20.09 46,33.49 39.33,20.09 			" />
                            <path class="st3" d="M39.33,1.31l18.77,18.78H39.33C39.33,20.09,39.33,1.43,39.33,1.31z" />
                        </g>
                        <g>
                            <polygon class="st1" points="24.76,16.72 38.93,41.06 1.1,28.77 			" />
                            <polyline class="st2" points="24.76,16.72 33.77,32.37 18.96,34.57 			" />
                            <path class="st3" d="M1.1,28.77l23.66-12.05l-5.8,17.85C18.96,34.57,1.22,28.81,1.1,28.77z" />
                        </g>
                        <g>
                            <polygon class="st1" points="11.25,47.38 38.78,41.44 15.4,73.61 			" />
                            <polyline class="st2" points="11.25,47.38 28.92,43.65 26.44,58.42 			" />
                            <path class="st3"
                                d="M15.4,73.61l-4.15-26.23l15.19,11.03C26.44,58.42,15.48,73.51,15.4,73.61z" />
                        </g>
                        <g>
                            <polygon class="st1" points="36.25,69.71 39.1,41.69 62.47,73.87 			" />
                            <polyline class="st2" points="36.25,69.71 38.16,51.75 51.43,58.67 			" />
                            <path class="st3"
                                d="M62.47,73.87l-26.23-4.16l15.19-11.03C51.43,58.67,62.4,73.77,62.47,73.87z" />
                        </g>
                        <g>
                            <polygon class="st1" points="65.2,52.84 39.44,41.47 77.26,29.18 			" />
                            <polyline class="st2" points="65.2,52.84 48.71,45.47 59.4,34.98 			" />
                            <path class="st3"
                                d="M77.26,29.18L65.2,52.84l-5.8-17.85C59.4,34.98,77.14,29.22,77.26,29.18z" />
                        </g>
                        <path class="st0" d="M77.49,28.79c-0.13-0.15-0.33-0.21-0.52-0.15l-0.02,0.01L40.49,40.5l17.87-19.98c0,0,0,0,0-0.01
                c0.02-0.02,0.04-0.04,0.05-0.07c0,0,0-0.01,0.01-0.01c0.01-0.02,0.02-0.03,0.03-0.05c0,0,0-0.01,0-0.01
                c0-0.01,0.01-0.02,0.01-0.03c0.01-0.02,0.01-0.04,0.01-0.05c0-0.01,0-0.02,0-0.03c0-0.02,0-0.04,0-0.06c0-0.01,0-0.01,0-0.02
                c0-0.03,0-0.05-0.01-0.08c0-0.01,0-0.01-0.01-0.02c-0.01-0.02-0.01-0.04-0.02-0.06c0-0.01-0.01-0.02-0.01-0.03
                c-0.01-0.02-0.02-0.03-0.03-0.05c0-0.01-0.01-0.02-0.01-0.02c-0.02-0.02-0.03-0.05-0.05-0.07L39.56,1.08
                c-0.14-0.14-0.35-0.18-0.53-0.11c-0.18,0.08-0.3,0.25-0.3,0.45v0.02v38.34L25.26,16.61c0,0,0,0,0-0.01
                c-0.01-0.02-0.03-0.05-0.05-0.07c0,0-0.01-0.01-0.01-0.01c-0.01-0.01-0.03-0.03-0.04-0.04c0,0-0.01,0-0.01-0.01
                c-0.01-0.01-0.02-0.01-0.02-0.02c-0.02-0.01-0.03-0.02-0.05-0.03c-0.01,0-0.02-0.01-0.03-0.01c-0.02-0.01-0.04-0.02-0.06-0.02
                c-0.01,0-0.01,0-0.02-0.01c-0.03-0.01-0.05-0.01-0.08-0.02c-0.01,0-0.01,0-0.02,0c-0.02,0-0.04,0-0.06,0c-0.01,0-0.02,0-0.03,0
                c-0.02,0-0.04,0.01-0.06,0.01c-0.01,0-0.02,0-0.03,0.01c-0.03,0.01-0.05,0.02-0.08,0.03L0.96,28.48
                c-0.17,0.09-0.28,0.27-0.26,0.47c0.02,0.2,0.15,0.36,0.33,0.42l0.02,0.01l36.46,11.85l-26.2,5.66c0,0,0,0-0.01,0
                c-0.03,0.01-0.05,0.01-0.08,0.03c0,0-0.01,0-0.01,0.01c-0.02,0.01-0.03,0.02-0.05,0.03c0,0-0.01,0.01-0.01,0.01
                c-0.01,0.01-0.02,0.01-0.02,0.02c-0.01,0.01-0.03,0.02-0.04,0.04c-0.01,0.01-0.01,0.01-0.02,0.02c-0.01,0.01-0.03,0.03-0.04,0.05
                c0,0.01-0.01,0.01-0.01,0.02c-0.02,0.02-0.03,0.05-0.04,0.07c0,0.01,0,0.01-0.01,0.02c-0.01,0.02-0.01,0.04-0.02,0.06
                c0,0.01,0,0.02-0.01,0.03c0,0.02-0.01,0.04-0.01,0.06c0,0.01,0,0.02,0,0.03c0,0.03,0,0.06,0.01,0.09l4.15,26.23
                c0.03,0.19,0.17,0.35,0.37,0.4c0.19,0.05,0.39-0.03,0.51-0.19l0.01-0.02L38.5,42.84L35.79,69.5c0,0,0,0,0,0.01
                c0,0.03,0,0.06,0,0.09c0,0,0,0.01,0,0.01c0,0.02,0,0.04,0.01,0.06c0,0,0,0.01,0,0.01c0,0.01,0.01,0.02,0.01,0.03
                c0.01,0.02,0.01,0.03,0.02,0.05c0,0.01,0.01,0.02,0.01,0.03c0.01,0.02,0.02,0.04,0.03,0.05c0,0.01,0.01,0.01,0.01,0.02
                c0.02,0.02,0.04,0.04,0.06,0.06c0,0,0.01,0.01,0.01,0.01c0.02,0.01,0.03,0.03,0.05,0.04c0.01,0.01,0.02,0.01,0.02,0.01
                c0.02,0.01,0.03,0.02,0.05,0.02c0.01,0,0.02,0.01,0.03,0.01c0.03,0.01,0.05,0.02,0.08,0.02l26.23,4.16
                c0.19,0.03,0.39-0.06,0.49-0.23c0.1-0.17,0.09-0.38-0.02-0.54l-0.01-0.02L40.34,42.39l24.52,10.82c0,0,0,0,0.01,0
                c0.03,0.01,0.05,0.02,0.08,0.03c0,0,0.01,0,0.01,0c0.02,0,0.04,0.01,0.06,0.01c0,0,0.01,0,0.01,0c0.01,0,0.02,0,0.03,0
                c0.02,0,0.04,0,0.06,0c0.01,0,0.02,0,0.03,0c0.02,0,0.04-0.01,0.06-0.02c0.01,0,0.01,0,0.02-0.01c0.03-0.01,0.05-0.02,0.07-0.03
                c0.01,0,0.01-0.01,0.02-0.01c0.02-0.01,0.04-0.02,0.05-0.04c0.01-0.01,0.01-0.01,0.02-0.02c0.01-0.01,0.03-0.03,0.04-0.04
                c0.01-0.01,0.01-0.01,0.02-0.02c0.02-0.02,0.03-0.05,0.05-0.07l12.06-23.66C77.64,29.15,77.61,28.94,77.49,28.79z M46.01,32.75
                L40,20.69h16.9L46.01,32.75z M56.36,19.26l0.46,0.46H39.7c0-2.45,0-13.48,0-17.12L56.36,19.26z M39.7,22.26l5.65,11.35l-5.65,6.31
                V22.26z M2.44,28.81l21-10.7l0.58-0.29L18.72,34.1C16.4,33.34,5.9,29.94,2.44,28.81z M24.96,18.05l8.11,14.09l-13.33,1.98
                L24.96,18.05z M33.68,33.02l4.26,7.32l-16.8-5.46L33.68,33.02z M15.86,72.35l-3.68-23.28l-0.1-0.64L25.92,58.5
                C24.48,60.48,18,69.41,15.86,72.35z M12.58,47.61l15.91-3.36l-2.23,13.29L12.58,47.61z M27.42,56.44l2.1-12.5l8.28-1.79
                L27.42,56.44z M61.42,73.05l-23.28-3.69l-0.64-0.1l13.85-10.06C52.79,61.17,59.27,70.1,61.42,73.05z M36.87,68.52l1.72-16.17
                l11.95,6.23L36.87,68.52z M38.62,51.27l0.86-8.43l10.38,14.29L38.62,51.27z M40.65,41.47l16.8-5.46l-9.05,8.88L40.65,41.47z
                M49.42,45.25l9.62-9.44l5.22,16.07L49.42,45.25z M65.45,50.93l-0.29,0.58l-5.29-16.28c2.33-0.76,12.82-4.17,16.29-5.29
                L65.45,50.93z" />
                    </g>
                </g>
            </svg>
            <span id="title">WebNN</span> Stable Diffusion
        </h1>
        <p id="error"></p>
    </div>
    <div class="container v9">
        <div class="left">
            <div class="input-group">
                <textarea placeholder="Enter your prompt" rows="2" type="text"
                    id="positive_prompt">giant castle, mountains, sunrise, volumetric lighting</textarea>
                <div class="tokeninfo">
                    <span id="positive_token_info">63/75 tokens left</span>
                </div>
            </div>
            <div class="input-group">
                <input type="text" id="negative_prompt" placeholder="negative prompt" />
                <div class="tokeninfo negative">
                    <span id="negative_token_info">75/75 tokens left</span>
                </div>
            </div>
            <div class="input-group grid-4 options">
                <div>
                    <div class="hide">
                        <label for="prompt">Seed</label>
                    </div>
                    <div class="grid-4-41 seed" title="Seed">
                        <input type="text" id="user_seed" value="123465" maxlength="6" minlength="6"></input>
                        <button id="change_seed" value="">
                            <svg xmlns="http://www.w3.org/2000/svg" height="24" viewBox="0 -960 960 960" width="24">
                                <path
                                    d="M204-318q-22-38-33-78t-11-82q0-134 93-228t227-94h7l-64-64 56-56 160 160-160 160-56-56 64-64h-7q-100 0-170 70.5T240-478q0 26 6 51t18 49l-60 60ZM481-40 321-200l160-160 56 56-64 64h7q100 0 170-70.5T720-482q0-26-6-51t-18-49l60-60q22 38 33 78t11 82q0 134-93 228t-227 94h-7l64 64-56 56Z" />
                            </svg>
                        </button>
                    </div>
                </div>
                <div></div>
                <div></div>
            </div>
            <div class="button-group key">
                <button id="load_models" class="button">
                    Load Models
                </button>
                <button id="generate_next_image" disabled>
                    <svg xmlns="http://www.w3.org/2000/svg" width="128" height="128" viewBox="0 0 256 256">
                        <path fill="#ffffff"
                            d="m197.58 129.06l-51.61-19l-19-51.65a15.92 15.92 0 0 0-29.88 0L78.07 110l-51.65 19a15.92 15.92 0 0 0 0 29.88L78 178l19 51.62a15.92 15.92 0 0 0 29.88 0l19-51.61l51.65-19a15.92 15.92 0 0 0 0-29.88ZM140.39 163a15.87 15.87 0 0 0-9.43 9.43l-19 51.46L93 172.39a15.87 15.87 0 0 0-9.39-9.39l-51.46-19l51.46-19a15.87 15.87 0 0 0 9.39-9.39l19-51.46l19 51.46a15.87 15.87 0 0 0 9.43 9.43l51.46 19ZM144 40a8 8 0 0 1 8-8h16V16a8 8 0 0 1 16 0v16h16a8 8 0 0 1 0 16h-16v16a8 8 0 0 1-16 0V48h-16a8 8 0 0 1-8-8m104 48a8 8 0 0 1-8 8h-8v8a8 8 0 0 1-16 0v-8h-8a8 8 0 0 1 0-16h8v-8a8 8 0 0 1 16 0v8h8a8 8 0 0 1 8 8" />
                    </svg>
                    Generate Image
                </button>
            </div>
            <div class="grid-2">
                <div class="progress">
                    <div class="progress-bar">
                        <div id="progress-bar-inner" class="progress-bar-inner"></div>
                    </div>
                    <div class="progress-bar-label" id="progress-bar-label">0%</div>
                </div>
                <div class="progress">
                    <div class="progress-bar">
                        <div id="progress-bar-inner-inference" class="progress-bar-inner"></div>
                    </div>
                    <div class="progress-bar-label" id="progress-bar-label-inference">0%</div>
                </div>
            </div>

            <div class="log-output" id='status'>
            </div>
            <div id="data" class="hide">
                <table>
                    <tr>
                        <th class="category"></th>
                        <th class="load">Load</th>
                        <th class="load">Model Fetch</th>
                        <th class="load">Session Create</th>
                        <th class="run">Execution (incl. Session Run)</th>
                    </tr>
                    <tr id="textencoder">
                        <td title="235MB">Text Encoder</td>
                        <td id="textencoderload"></td>
                        <td id="textencoderfetch" title="235MB"></td>
                        <td id="textencodercreate"></td>
                        <td id="textencoderrun"></td>
                    </tr>
                    <tr id="unet">
                        <td title="1.60GB">UNet</td>
                        <td id="unetload"></td>
                        <td id="unetfetch" title="1.60GB"></td>
                        <td id="unetcreate"></td>
                        <td id="unetrun"></td>
                    </tr>
                    <tr id="vaedecoder">
                        <td title="94.5MB">VAE Decoder</td>
                        <td id="vaedecoderload"></td>
                        <td id="vaedecoderfetch" title="94.5MB"></td>
                        <td id="vaedecodercreate"></td>
                        <td id="vaedecoderrun"></td>
                    </tr>
                    <tr id="total">
                        <td>Total</td>
                        <td id="totalload"></td>
                        <td id="totalfetch">-</td>
                        <td id="totalcreate">-</td>
                        <td id="totalrun"></td>
                    </tr>
                </table>
            </div>
            <div id="webnnstatus"><span id="circle"></span> <span id="info">WebNN</span></div>
            <div id="ortversion"></div>
        </div>
        <div class="right">
            <div>
                <canvas class='canvas' id='canvas' width='512' height='512'>
                    Canvas is not supported. You'll need to try a newer browser version or another browser.
                </canvas>
            </div>
        </div>
    </div>
</body>

<script type='module'>
    import * as Utils from './utils.js';

    // Configuration...
    const pixelWidth = 512;
    const pixelHeight = 512;
    const latentWidth = (pixelWidth / 8);
    const latentHeight = (pixelHeight / 8);
    const latentChannelCount = 4;
    const unetBatch = 2;
    const unetChannelCount = 4;
    const textEmbeddingSequenceLength = 77;
    const textEmbeddingSequenceWidth = 768;
    const unetIterationCount = 25; // Hard-coded number of samples, since the denoising weight ramp is constant.
    let seed = BigInt(123465);
    let performanceData = {
        loadtime: {
            textencoder: 0,
            unet: 0,
            vaedecoder: 0,
            total: 0
        },
        modelfetch: {
            textencoder: 0,
            unet: 0,
            vaedecoder: 0,
        },
        sessioncreate: {
            textencoder: 0,
            unet: 0,
            vaedecoder: 0,
        },
        sessionrun: {
            textencoder: 0,
            unet: [],
            unettotal: 0,
            vaedecoder: 0,
            total: 0
        }
    };

    function to(promise, errorExt) {
        return promise
            .then(function (data) { return [null, data]; })
            .catch(function (err) {
                if (errorExt) {
                    Object.assign(err, errorExt);
                }
                return [err, undefined];
            });
    }

    const setupORT = async () => {
        const ortversion = document.querySelector('#ortversion');
        Utils.removeElement('onnxruntime-web');
        let ortVersion = await Utils.getOrtDevVersion();
        let ortLink = '';
        if (ortVersion && ortVersion.length > 4) {
            await Utils.loadScript('onnxruntime-web', `https://cdn.jsdelivr.net/npm/onnxruntime-web@${ortVersion}/dist/ort.all.min.js`);
            ortLink = `https://www.npmjs.com/package/onnxruntime-web/v/${ortVersion}`
            ortversion.innerHTML = `ONNX Runtime Web: <a href="${ortLink}">${ortVersion}</a><br/>[To do: Use WebNN EP of ORT Web 1.18 release version]`;
        } else {
            await Utils.loadScript('onnxruntime-web', './dist/ort.all.min.js');
            ortversion.innerHTML = `ONNX Runtime Web: Test version`;
        }
    }

    let progress = 0;
    let fetchProgress = 0;
    let textEncoderFetchProgress = 0;
    let unetFetchProgress = 0;
    let vaeDecoderFetchProgress = 0;

    // Get model via Origin Private File System
    async function getModelOPFS(name, url, updateModel) {
        const root = await navigator.storage.getDirectory();
        let fileHandle;

        async function updateFile() {
            const response = await fetch(url);
            const buffer = await readResponse(name, response);
            fileHandle = await root.getFileHandle(name, { create: true });
            const writable = await fileHandle.createWritable();
            await writable.write(buffer);
            await writable.close();
            return buffer;
        }

        if (updateModel) {
            return await updateFile();
        }

        try {
            fileHandle = await root.getFileHandle(name);
            const blob = await fileHandle.getFile();
            let buffer = await blob.arrayBuffer();
            if (buffer) {
                if (name == 'text-encoder') {
                    textEncoderFetchProgress = 10;
                } else if (name == 'stable-diffusion-unet') {
                    unetFetchProgress = 80;
                } else if (name == 'stable-diffusion-vae-decoder') {
                    vaeDecoderFetchProgress = 5;
                }

                progress = textEncoderFetchProgress + unetFetchProgress + vaeDecoderFetchProgress;
                progressBarInner.style.width = progress + "%";

                if (name == 'text-encoder') {
                    progressBarLabel.textContent = "Loading Text Encoder model · 235MB · " + progress.toFixed(2) + "%";
                } else if (name == 'stable-diffusion-unet') {
                    progressBarLabel.textContent = "Loading UNet model · 1.60GB · " + progress.toFixed(2) + "%";
                } else if (name == 'stable-diffusion-vae-decoder') {
                    progressBarLabel.textContent = "Loading VAE Decoder model · 94.5MB · " + progress.toFixed(2) + "%";
                }

                return buffer;
            }

        } catch (e) {
            return await updateFile();
        }
    }

    async function readResponse(name, response) {
        const contentLength = response.headers.get('Content-Length');
        let total = parseInt(contentLength ?? '0');
        let buffer = new Uint8Array(total);
        let loaded = 0;

        const reader = response.body.getReader();
        async function read() {
            const { done, value } = await reader.read();
            if (done) return;

            let newLoaded = loaded + value.length;
            fetchProgress = (newLoaded / contentLength) * 100;

            if (name == 'text-encoder') {
                textEncoderFetchProgress = 0.1 * fetchProgress;
            } else if (name == 'stable-diffusion-unet') {
                unetFetchProgress = 0.8 * fetchProgress;
            } else if (name == 'stable-diffusion-vae-decoder') {
                vaeDecoderFetchProgress = 0.05 * fetchProgress;
            }

            progress = textEncoderFetchProgress + unetFetchProgress + vaeDecoderFetchProgress;
            progressBarInner.style.width = progress + "%";

            if (name == 'text-encoder') {
                progressBarLabel.textContent = "Loading Text Encoder model · 235MB · " + progress.toFixed(2) + "%";
            } else if (name == 'stable-diffusion-unet') {
                progressBarLabel.textContent = "Loading UNet model · 1.60GB · " + progress.toFixed(2) + "%";
            } else if (name == 'stable-diffusion-vae-decoder') {
                progressBarLabel.textContent = "Loading VAE Decoder model · 94.5MB · " + progress.toFixed(2) + "%";
            }

            if (newLoaded > total) {
                total = newLoaded;
                let newBuffer = new Uint8Array(total);
                newBuffer.set(buffer);
                buffer = newBuffer;
            }
            buffer.set(value, loaded);
            loaded = newLoaded;
            return read();
        }

        await read();
        return buffer;
    }

    Utils.log('[Load] Loading ONNX Runtime');
    const progressBarInner = document.getElementById("progress-bar-inner");
    const progressBarLabel = document.getElementById("progress-bar-label");
    const progressBarInnerInference = document.querySelector("#progress-bar-inner-inference");
    const progressBarLabelInference = document.querySelector("#progress-bar-label-inference");
    const startButton = document.getElementById('generate_next_image');
    const loadButton = document.getElementById('load_models');
    const logOutput = document.getElementById("status");
    const positiveInput = document.getElementById('positive_prompt');
    const negativeInput = document.getElementById('negative_prompt');
    const positiveTokenInfo = document.getElementById('positive_token_info');
    const negativeTokenInfo = document.getElementById('negative_token_info');
    const error = document.querySelector('#error');
    const userSeed = document.querySelector('#user_seed');
    const changeSeed = document.querySelector('#change_seed');
    const title = document.querySelector('#title');
    const data = document.querySelector('#data');
    const textEncoderLoad = document.querySelector('#textencoderload');
    const textEncoderFetch = document.querySelector('#textencoderfetch');
    const textEncoderCreate = document.querySelector('#textencodercreate');
    const textEncoderRun = document.querySelector('#textencoderrun');
    const unetLoad = document.querySelector('#unetload');
    const unetFetch = document.querySelector('#unetfetch');
    const unetCreate = document.querySelector('#unetcreate');
    const unetRun = document.querySelector('#unetrun');
    const vaeDecoderLoad = document.querySelector('#vaedecoderload');
    const vaeDecoderFetch = document.querySelector('#vaedecoderfetch');
    const vaeDecoderCreate = document.querySelector('#vaedecodercreate');
    const vaeDecoderRun = document.querySelector('#vaedecoderrun');
    const totalLoad = document.querySelector('#totalload');
    const totalRun = document.querySelector('#totalrun');
    let inferenceProgress = 0;

    loadButton.onclick = async () => {
        progress = 0;
        fetchProgress = 0;
        textEncoderFetchProgress = 0;
        unetFetchProgress = 0;
        vaeDecoderFetchProgress = 0;

        data.removeAttribute('class');
        data.setAttribute('class', 'hide');

        performanceData.loadtime.textencoder = 0;
        performanceData.loadtime.unet = [];
        performanceData.loadtime.vaedecoder = 0;
        performanceData.loadtime.total = 0

        performanceData.modelfetch.textencoder = 0;
        performanceData.modelfetch.unet = 0;
        performanceData.modelfetch.vaedecoder = 0;

        performanceData.sessioncreate.textencoder = 0;
        performanceData.sessioncreate.unet = 0;
        performanceData.sessioncreate.vaedecoder = 0;

        loadButton.disabled = true;
        startButton.disabled = true;
        await loadStableDiffusion(executionProvider);
        startButton.disabled = false;

        if (performanceData.loadtime.total) {
            textEncoderLoad.innerHTML = performanceData.loadtime.textencoder
            textEncoderFetch.innerHTML = performanceData.modelfetch.textencoder;
            textEncoderCreate.innerHTML = performanceData.sessioncreate.textencoder;
            textEncoderRun.innerHTML = '-';

            unetLoad.innerHTML = performanceData.loadtime.unet;
            unetFetch.innerHTML = performanceData.modelfetch.unet;
            unetCreate.innerHTML = performanceData.sessioncreate.unet;
            unetRun.innerHTML = '-';

            vaeDecoderLoad.innerHTML = performanceData.loadtime.vaedecoder;
            vaeDecoderFetch.innerHTML = performanceData.modelfetch.vaedecoder;
            vaeDecoderCreate.innerHTML = performanceData.sessioncreate.vaedecoder;
            vaeDecoderRun.innerHTML = '-';

            totalLoad.innerHTML = performanceData.loadtime.total;
            totalRun.innerHTML = '-';
        }

        data.setAttribute('class', 'show');
    }

    startButton.onclick = async () => {
        performanceData.sessionrun.textencoder = 0;
        performanceData.sessionrun.unet = [];
        performanceData.sessionrun.unettotal = 0;
        performanceData.sessionrun.vaedecoder = 0;
        performanceData.sessionrun.total = 0

        startButton.disabled = true;
        await generateNextImage();
        inferenceProgress = 0;
    }

    positiveInput.addEventListener('input', async (e) => {
        const inputValue = e.target.value;
        const ids = await Utils.getTokenizers(inputValue);
        // Max token length is 75.
        const left_tokens_length = 75 - ids.length;
        positiveTokenInfo.innerHTML = `${(left_tokens_length <= 0) ? 0 : left_tokens_length}/75`;
    });

    negativeInput.addEventListener('input', async (e) => {
        const inputValue = e.target.value;
        const ids = await Utils.getTokenizers(inputValue);
        // Max token length is 75.
        const left_tokens_length = 75 - ids.length;
        negativeTokenInfo.innerHTML = `${(left_tokens_length <= 0) ? 0 : left_tokens_length}/75`;
    });

    async function getTextTokens() {
        const positiveText = positiveInput.value;
        const negativeText = negativeInput.value;

        // A string like 'a cute magical flying ghost dog, fantasy art, golden color, high quality, highly detailed, elegant, sharp focus, concept art, character concepts, digital painting, mystery, adventure'
        // becomes a 1D tensor of {49406, 320, 2242, 7823, 4610, 7108, 1929, 267, 5267, 794, 267, 3878, 3140, 267, 1400, 3027, ...}
        // padded with blanks (id 49407) up to the maximum sequence length of the text encoder (typically 77).
        // So the text encoder can't really handle more than 75 words (+1 start, +1 stop token),
        // not without some extra tricks anyway like calling it multiple times and combining the embeddings.
        let positive_token_ids = [49406]; // Inits with start token
        let negative_token_ids = [49406];
        const positive_text_ids = await Utils.getTokenizers(positiveText);
        positive_token_ids = positive_token_ids.concat(positive_text_ids);
        if (positive_text_ids.length > (textEmbeddingSequenceLength - 2)) { // Max inputs ids should be 75
            positive_token_ids = positive_token_ids.slice(0, (textEmbeddingSequenceLength - 1));
            positive_token_ids.push(49407);
        } else {
            const fillerArray = new Array(textEmbeddingSequenceLength - positive_token_ids.length).fill(49407);
            positive_token_ids = positive_token_ids.concat(fillerArray);
        }

        let negative_text_ids = await Utils.getTokenizers(negativeText);
        negative_token_ids = negative_token_ids.concat(negative_text_ids);
        if (negative_text_ids.length > (textEmbeddingSequenceLength - 2)) {
            negative_token_ids = negative_token_ids.slice(0, (textEmbeddingSequenceLength - 1));
            negative_token_ids.push(49407);
        } else {
            const fillerArray = new Array(textEmbeddingSequenceLength - negative_token_ids.length).fill(49407);
            negative_token_ids = negative_token_ids.concat(fillerArray);
        }

        const token_ids = positive_token_ids.concat(negative_token_ids);
        return token_ids;
    };

    Utils.log('[Load] ONNX Runtime loaded');

    function convertPlanarFloat16RgbToUint8Rgba(input /*Uint16Array*/, width, height) {
        let totalPixelCount = width * height;
        let totalOutputBytes = totalPixelCount * 4;

        let redInputOffset = 0;
        let greenInputOffset = redInputOffset + totalPixelCount;
        let blueInputOffset = greenInputOffset + totalPixelCount;

        const rgba = new Uint8ClampedArray(totalOutputBytes);
        for (let i = 0, j = 0; i < totalPixelCount; i++, j += 4) {
            rgba[j + 0] = (Utils.decodeFloat16(input[redInputOffset + i]) + 1.0) * (255.0 / 2.0);
            rgba[j + 1] = (Utils.decodeFloat16(input[greenInputOffset + i]) + 1.0) * (255.0 / 2.0);
            rgba[j + 2] = (Utils.decodeFloat16(input[blueInputOffset + i]) + 1.0) * (255.0 / 2.0);
            rgba[j + 3] = 255;
        }
        return rgba;
    }

    function convertPlanarUint8RgbToUint8Rgba(input /*Uint16Array*/, width, height) {
        let totalPixelCount = width * height;
        let totalOutputBytes = totalPixelCount * 4;

        let redInputOffset = 0;
        let greenInputOffset = redInputOffset + totalPixelCount;
        let blueInputOffset = greenInputOffset + totalPixelCount;

        const rgba = new Uint8ClampedArray(totalOutputBytes);
        for (let i = 0, j = 0; i < totalPixelCount; i++, j += 4) {
            let inputValue = input[redInputOffset + i];
            rgba[j + 0] = inputValue;
            rgba[j + 1] = inputValue;
            rgba[j + 2] = inputValue;
            rgba[j + 3] = 255;
        }
        return rgba;
    }

    function convertPlanarFloat32RgbToUint8Rgba(input /*Uint16Array*/, width, height) {
        let totalPixelCount = width * height;
        let totalOutputBytes = totalPixelCount * 4;

        let redInputOffset = 0;
        let greenInputOffset = redInputOffset + totalPixelCount;
        let blueInputOffset = greenInputOffset + totalPixelCount;

        const rgba = new Uint8ClampedArray(totalOutputBytes);
        for (let i = 0, j = 0; i < totalPixelCount; i++, j += 4) {
            rgba[j + 0] = (input[redInputOffset + i] + 1.0) * (255.0 / 2.0);
            rgba[j + 1] = (input[greenInputOffset + i] + 1.0) * (255.0 / 2.0);
            rgba[j + 2] = (input[blueInputOffset + i] + 1.0) * (255.0 / 2.0);
            rgba[j + 3] = 255;
        }
        return rgba;
    }

    async function loadModel(modelName/*:String*/, executionProvider/*:String*/) {
        let modelPath;
        let modelSession;
        let freeDimensionOverrides;
        let modelSize;

        if (modelName == 'text-encoder') {
            modelSize = '235MB';
        } else if (modelName == 'stable-diffusion-unet') {
            modelSize = '1.60GB';
        } else if (modelName == 'stable-diffusion-vae-decoder') {
            modelSize = '94.5MB';
        }

        Utils.log(`[Load] Loading model ${modelName} · ${modelSize}`);
        if (modelName == 'text-encoder') {
            //  Inputs:
            //    int32 input_ids[batch,sequence]
            //    batch: 2
            //    sequence: 77
            //  Outputs:
            //    float16 last_hidden_state[Addlast_hidden_state_dim_0,Addlast_hidden_state_dim_1,768]
            //    float16 pooler_output[Addlast_hidden_state_dim_0,768] We don't care about this ignorable output.
            //    Addlast_hidden_state_dim_0: 2
            //    Addlast_hidden_state_dim_1: 77
            // modelPath = 'models/Stable-Diffusion-v1.5-text-encoder-float16.onnx';
            modelPath = Utils.modelPath() + 'text-encoder.onnx'
            freeDimensionOverrides = {
                'batch': unetBatch,
                'sequence': textEmbeddingSequenceLength,
            }
        }
        else if (modelName == 'stable-diffusion-unet') {
            //  Typical shapes (some models may vary, like inpainting have 9 channels or single batch having 1 batch)...
            //
            //  Inputs:
            //    float16 sample[2, 4, 64, 64]
            //    int64 timestep[2]
            //    float16 encoder_hidden_states[2, 77, 768]
            //  Outputs:
            //    float16 out_sample[2, 4, 64, 64]
            modelPath = Utils.modelPath() + 'sd-unet-v1.5-model-b2c4h64w64s77-float16-compute-and-inputs.onnx';

            freeDimensionOverrides =
            {
                'batch': unetBatch,
                'channels': unetChannelCount,
                'height': latentHeight,
                'width': latentWidth,
                'sequence': textEmbeddingSequenceLength,
                'unet_sample_batch': unetBatch,
                'unet_sample_channels': unetChannelCount,
                'unet_sample_height': latentHeight,
                'unet_sample_width': latentWidth,
                'unet_time_batch': unetBatch,
                'unet_hidden_batch': unetBatch,
                'unet_hidden_sequence': textEmbeddingSequenceLength,
            };
        }
        else if (modelName == 'stable-diffusion-vae-decoder') {
            //  Inputs:
            //    float16 latent_sample[1, 4, 64, 64]
            //  Outputs:
            //    float16 sample[1, 3, 512, 512]
            modelPath = Utils.modelPath() + 'Stable-Diffusion-v1.5-vae-decoder-float16-fp32-instancenorm.onnx';
            freeDimensionOverrides = { 'batch': 1, 'channels': latentChannelCount, 'height': latentHeight, 'width': latentWidth, };
        }
        else {
            throw new Error(`Model ${modelName} is unknown`);
        }

        const options =
        {
            executionProviders: [{ name: executionProvider, deviceType: Utils.getQueryVariable('device', 'gpu'), powerPreference: 'default' }],
        };

        if (freeDimensionOverrides != undefined) {
            options.freeDimensionOverrides = freeDimensionOverrides;
        }

        options.logSeverityLevel = 3;

        Utils.log('[Load] Model path = ' + modelPath);
        let modelBuffer;

        let fetchStartTime = performance.now();
        modelBuffer = await getModelOPFS(modelName, modelPath, false);
        let fetchTime = (performance.now() - fetchStartTime).toFixed(2);

        if (modelName == 'text-encoder') {
            performanceData.modelfetch.textencoder = fetchTime;
            progressBarLabel.textContent = `Loaded Text Encoder · ${(fetchTime / 1000).toFixed(2)}s · 10%`;
            Utils.log(`[Load] Text Encoder loaded · ${(fetchTime / 1000).toFixed(2)}s`);

            progressBarLabel.textContent = 'Creating session for Text Encoder · 10%';
            Utils.log('[Session Create] Beginning text encode');
        } else if (modelName == 'stable-diffusion-unet') {
            performanceData.modelfetch.unet = fetchTime;
            progressBarLabel.textContent = `Loaded UNet · ${(fetchTime / 1000).toFixed(2)}s · 90%`;
            Utils.log(`[Load] UNet loaded · ${(fetchTime / 1000).toFixed(2)}s`);

            progressBarLabel.textContent = 'Creating session for UNet · 90%'
            Utils.log('[Session Create] Beginning UNet');
        } else if (modelName == 'stable-diffusion-vae-decoder') {
            performanceData.modelfetch.vaedecoder = fetchTime;
            progressBarLabel.textContent = `Loaded VAE Decoder · ${(fetchTime / 1000).toFixed(2)}s · 95%`;
            Utils.log(`[Load] VAE Decoder loaded · ${(fetchTime / 1000).toFixed(2)}s`);

            progressBarLabel.textContent = 'Creating session for VAE Decoder · 95%'
            Utils.log('[Session Create] Beginning VAE decode');
        }

        let createStartTime = performance.now();
        modelSession = await ort.InferenceSession.create(modelBuffer, options);

        if (modelName == 'text-encoder') {
            let textencoderCreateTime = (performance.now() - createStartTime).toFixed(2);
            performanceData.sessioncreate.textencoder = textencoderCreateTime;
            progressBarLabel.textContent = `Text Encoder session created · ${textencoderCreateTime}ms · 10%`
            Utils.log(`[Session Create] Text Encoder completed · ${textencoderCreateTime}ms`);
        } else if (modelName == 'stable-diffusion-unet') {
            let unetCreateTime = (performance.now() - createStartTime).toFixed(2);
            performanceData.sessioncreate.unet = unetCreateTime;
            progressBarLabel.textContent = `UNet session created · ${unetCreateTime}ms · 90%`
            Utils.log(`[Session Create] UNet Completed · ${unetCreateTime}ms`);
        } else if (modelName == 'stable-diffusion-vae-decoder') {
            let vaedecoderCreateTime = (performance.now() - createStartTime).toFixed(2);
            performanceData.sessioncreate.vaedecoder = vaedecoderCreateTime;
            progressBarLabel.textContent = `VAE Decoder session created · ${vaedecoderCreateTime}ms · 95%`
            Utils.log(`[Session Create] VAE Decoder completed · ${vaedecoderCreateTime}ms`);
        }
        return modelSession;
    }

    function displayEmptyCanvasPlaceholder() {
        const canvas = document.getElementById('canvas');
        const context = canvas.getContext('2d');
        context.fillStyle = 'rgba(255, 255, 255, 0.5)';
        context.strokeStyle = 'rgba(255, 255, 255, 0.0)';
        context.lineWidth = 0;
        //context.fillRect(0, 0, pixelWidth, pixelHeight);
        context.textAlign = 'center';
        context.textBaseline = 'middle';
        context.font = '300px sans-serif';
        context.fillText('🖼️', canvas.width / 2, canvas.height / 2);
        context.strokeRect(0, 0, pixelWidth, pixelHeight);
    }

    function displayPlanarRGB(planarPixelData/*: Float32Array or Uint16Array as float16 or Uint8Array*/) {
        const canvas = document.getElementById('canvas');
        const context = canvas.getContext('2d');

        // TODO: See if ORT's toImageData() is flexible enough to handle this instead.
        // It doesn't appear work correctly, just returning all white (shrug, maybe I'm passing the wrong values).
        // https://onnxruntime.ai/docs/api/js/interfaces/Tensor-1.html#toImageData
        // https://github.com/microsoft/onnxruntime/blob/5228332/js/common/lib/tensor-conversion.ts#L33
        // https://github.com/microsoft/onnxruntime/blob/main/js/common/lib/tensor-factory.ts#L147
        //
        // let imageData = planarPixelTensor.toImageData({format: 'RGB', tensorLayout: 'NCHW', norm:{bias: 1, mean: 128}});

        let conversionFunction = planarPixelData instanceof Float32Array
            ? convertPlanarFloat32RgbToUint8Rgba
            : planarPixelData instanceof Uint16Array
                ? convertPlanarFloat16RgbToUint8Rgba
                : convertPlanarUint8RgbToUint8Rgba;

        let rgbaPixels = conversionFunction(planarPixelData, pixelWidth, pixelHeight);

        let imageData = new ImageData(rgbaPixels, pixelWidth, pixelHeight);
        context.putImageData(imageData, 0, 0);
    }

    let textEncoderSession;
    let vaeDecoderModelSession;
    let unetModelSession;

    // Hard-coded values for 25 iterations (the standard).
    const defaultSigmas/*[25 + 1]*/ = [14.614647, 11.435942, 9.076809, 7.3019943, 5.9489183, 4.903778, 4.0860896, 3.4381795, 2.9183085, 2.495972, 2.1485956, 1.8593576, 1.6155834, 1.407623, 1.2280698, 1.0711612, 0.9323583, 0.80802417, 0.695151, 0.5911423, 0.49355352, 0.3997028, 0.30577788, 0.20348993, 0.02916753, 0.0];
    const defaultTimeSteps/*[25]*/ = [999.0, 957.375, 915.75, 874.125, 832.5, 790.875, 749.25, 707.625, 666.0, 624.375, 582.75, 541.125, 499.5, 457.875, 416.25, 374.625, 333.0, 291.375, 249.75, 208.125, 166.5, 124.875, 83.25, 41.625, 0.0];

    async function initializeOnnxRuntime() {
        // Global singletons -_-. Initialize ORT's global singleton.
        ort.env.wasm.numThreads = 1; // 4
        ort.env.wasm.simd = true;
        ort.env.wasm.proxy = false;
    }

    async function loadStableDiffusion(executionProvider) {
        try {
            // Release sessions if load models again.
            if (textEncoderSession) {
                await unetModelSession.release();
                await textEncoderSession.release();
                await vaeDecoderModelSession.release();
            }

            error.removeAttribute("class");
            error.innerHTML = '';

            const loadStartTime = performance.now();
            textEncoderSession = await loadModel('text-encoder', executionProvider);
            performanceData.loadtime.textencoder = (performance.now() - loadStartTime).toFixed(2);

            const unetLoadStartTime = performance.now();
            unetModelSession = await loadModel('stable-diffusion-unet', executionProvider);
            performanceData.loadtime.unet = (performance.now() - unetLoadStartTime).toFixed(2);

            const vaeDecoderLoadStartTime = performance.now();
            vaeDecoderModelSession = await loadModel('stable-diffusion-vae-decoder', executionProvider);
            performanceData.loadtime.vaedecoder = (performance.now() - vaeDecoderLoadStartTime).toFixed(2);

            progress += 5;
            progressBarInner.style.width = progress + "%";
            progressBarLabel.textContent = "Models loaded and sessions created · " + progress.toFixed(2) + "%";
            const loadTime = performance.now() - loadStartTime;
            Utils.log(`[Total] Total load time (models load and sessions creation): ${(loadTime / 1000).toFixed(2)}s`);
            performanceData.loadtime.total = loadTime.toFixed(2);
            startButton.removeAttribute('disabled');
        }
        catch (e) {
            console.log('Exception: ', e);
            error.setAttribute("class", "error");
            error.innerHTML = e.message;
            Utils.appendStatus('Exception: ' + e);
        }
    }

    function practRandSimpleFastCounter32(a, b, c, d)
    // https://pracrand.sourceforge.net/
    // Using this as a substitute for std::minstd_rand instead.
    // (std::linear_congruential_engine<std::uint_fast32_t, 48271, 0, 2147483647>).
    {
        return function () {
            a >>>= 0; b >>>= 0; c >>>= 0; d >>>= 0;
            var t = (a + b) | 0;
            a = b ^ b >>> 9;
            b = c + (c << 3) | 0;
            c = (c << 21 | c >>> 11);
            d = d + 1 | 0;
            t = t + d | 0;
            c = c + t | 0;
            return (t >>> 0) / 4294967296;
        };
    }

    function generateNoise(/*out*/ latentSpace/*: Uint16Array*/, seed/*: BigInt*/) {
        // Don't know nearly equivalent to .

        let randomGenerator = practRandSimpleFastCounter32(
            Number(seed >> 0n) & 0xFFFFFFFF,
            Number(seed >> 32n) & 0xFFFFFFFF,
            Number(seed >> 64n) & 0xFFFFFFFF,
            Number(seed >> 96n) & 0xFFFFFFFF
        );

        const elementCount = latentSpace.length;
        for (let i = 0; i < elementCount; ++i) {
            const u1 = randomGenerator();
            const u2 = randomGenerator();
            const radius = Math.sqrt(-2.0 * Math.log(u1));
            const theta = 2.0 * Math.PI * u2;
            const standardNormalRand = radius * Math.cos(theta);
            const newValue = standardNormalRand;
            latentSpace[i] = Utils.encodeFloat16(newValue);
        }
    }

    function prescaleLatentSpace(/*inout*/ latentSpace/*: Uint16Array*/, initialSigma/*: float*/) {
        const elementCount = latentSpace.length;
        for (let i = 0; i < elementCount; ++i) {
            latentSpace[i] = Utils.encodeFloat16(Utils.decodeFloat16(latentSpace[i]) * initialSigma);
        }
    }

    function scaleLatentSpaceForPrediction(/*inout*/ latentSpace/*: Uint16Array*/, iterationIndex/*: int*/) {
        console.assert(iterationIndex < defaultSigmas.length);

        // sample = sample / ((sigma**2 + 1) ** 0.5)
        let sigma = defaultSigmas[iterationIndex];
        let inverseScale = 1 / Math.sqrt(sigma * sigma + 1);

        const elementCount = latentSpace.length;
        for (let i = 0; i < elementCount; ++i) {
            latentSpace[i] = Utils.encodeFloat16(Utils.decodeFloat16(latentSpace[i]) * inverseScale);
        }
    }

    // Adjusts the latent space in-place by the predicted noise, weighted for the current iteration.
    // This version takes two batches, with the positive prediction in batch 0, negative in batch 1.
    function denoiseLatentSpace(/*inout*/ latentSpace/*: Uint16Array*/, iterationIndex/*: Number*/, predictedNoise/*: Uint16Array*/) {
        console.assert(latentSpace.length === predictedNoise.length);

        const elementCount = latentSpace.length;          // Given [2, 4, 64, 64], count of all elements.
        const singleBatchElementCount = elementCount / 2; // Given [2, 4, 64, 64], we want only the first batch.

        // Prompt strength scale.
        const defaultPromptStrengthScale = 7.5;
        const positiveWeight = defaultPromptStrengthScale;
        const negativeWeight = 1 - positiveWeight;

        // Add predicted noise (scaled by current iteration weight) to latents.
        const sigma = defaultSigmas[iterationIndex];
        const sigmaNext = defaultSigmas[iterationIndex + 1];
        const dt = sigmaNext - sigma;

        for (let i = 0; i < singleBatchElementCount; ++i) {
            // Fold 2 batches into one, weighted by positive and negative weights.
            const weightedPredictedNoise = Utils.decodeFloat16(predictedNoise[i]) * positiveWeight + Utils.decodeFloat16(predictedNoise[i + singleBatchElementCount]) * negativeWeight;

            // The full formula:
            //
            //  // 1. Compute predicted original sample from sigma-scaled predicted noise.
            //  float sample = latentSpace[i];
            //  float predictedOriginalSample = sample - sigma * predictedNoiseData[i];
            // 
            //  // 2. Convert to an ODE derivative
            //  float derivative = (sample - predictedOriginalSample) / sigma;
            //  float previousSample = sample + derivative * dt;
            //  latentSpace[i] = previousSample;
            //
            // Simplifies to:
            //
            //  updatedSample = sample + ((sample - (sample - sigma * predictedNoiseData[i])) / sigma  * dt);
            //  updatedSample = sample + ((sample - sample + sigma * predictedNoiseData[i]) / sigma  * dt);
            //  updatedSample = sample + ((sigma * predictedNoiseData[i]) / sigma  * dt);
            //  updatedSample = sample + (predictedNoiseData[i] * dt);

            latentSpace[i] = Utils.encodeFloat16(Utils.decodeFloat16(latentSpace[i]) + weightedPredictedNoise * dt);
        }
    }

    // Adjusts the latent space in-place by the predicted noise, weighted for the current iteration.
    // This version takes two separate predicted noise arrays.
    function denoiseLatentSpaceSplitPredictions(/*inout*/ latentSpace/*: Uint16Array*/, iterationIndex/*: Number*/, positivePredictedNoise/*: Uint16Array*/, negativePredictedNoise/*: Uint16Array*/) {
        console.assert(latentSpace.length === positivePredictedNoise.length);
        console.assert(latentSpace.length === negativePredictedNoise.length);

        const elementCount = latentSpace.length;          // Given [2, 4, 64, 64], count of all elements.

        // Prompt strength scale.
        const defaultPromptStrengthScale = 7.5;
        const positiveWeight = defaultPromptStrengthScale;
        const negativeWeight = 1 - positiveWeight;

        // Add predicted noise (scaled by current iteration weight) to latents.
        const sigma = defaultSigmas[iterationIndex];
        const sigmaNext = defaultSigmas[iterationIndex + 1];
        const dt = sigmaNext - sigma;

        for (let i = 0; i < elementCount; ++i) {
            // Fold 2 batches into one, weighted by positive and negative weights.
            const weightedPredictedNoise = Utils.decodeFloat16(positivePredictedNoise[i]) * positiveWeight + Utils.decodeFloat16(negativePredictedNoise[i]) * negativeWeight;

            // The full formula:
            //
            //  // 1. Compute predicted original sample from sigma-scaled predicted noise.
            //  float sample = latentSpace[i];
            //  float predictedOriginalSample = sample - sigma * predictedNoiseData[i];
            // 
            //  // 2. Convert to an ODE derivative
            //  float derivative = (sample - predictedOriginalSample) / sigma;
            //  float previousSample = sample + derivative * dt;
            //  latentSpace[i] = previousSample;
            //
            // Simplifies to:
            //
            //  updatedSample = sample + ((sample - (sample - sigma * predictedNoiseData[i])) / sigma  * dt);
            //  updatedSample = sample + ((sample - sample + sigma * predictedNoiseData[i]) / sigma  * dt);
            //  updatedSample = sample + ((sigma * predictedNoiseData[i]) / sigma  * dt);
            //  updatedSample = sample + (predictedNoiseData[i] * dt);

            latentSpace[i] = Utils.encodeFloat16(Utils.decodeFloat16(latentSpace[i]) + weightedPredictedNoise * dt);
        }
    }

    function applyVaeScalingFactor(latentSpace/*: Uint16Array as float16*/) {
        const /*float*/ defaultVaeScalingFactor = 0.18215; // Magic constants for default VAE :D (used in Huggingface pipeline).
        const /*float*/ inverseScalingFactor = 1.0 / defaultVaeScalingFactor;
        latentSpace.forEach((e, i, a) => a[i] = Utils.encodeFloat16(Utils.decodeFloat16(e) * inverseScalingFactor));
    }

    async function executeStableDiffusion()/*: ort.Tensor*/
    // Implicit inputs:
    // - unetModelSession
    // - unetInputs
    // - vaeDecoderInputs
    {
        Utils.log('[Session Run] Beginning text encode');
        let token_ids = await getTextTokens();
        const startTextEncoder = performance.now();
        const textEncoderInputs = {
            'input_ids': Utils.generateTensorFromValues('int32', [unetBatch, textEmbeddingSequenceLength], token_ids),
        };
        const textEncoderOutputs = await textEncoderSession.run(textEncoderInputs);

        let textEncoderExecutionTime = (performance.now() - startTextEncoder).toFixed(2);
        performanceData.sessionrun.textencoder = textEncoderExecutionTime;
        Utils.log(`[Session Run] Text encode execution time: ${textEncoderExecutionTime}ms`);

        inferenceProgress += 1;
        progressBarInnerInference.style.width = inferenceProgress + "%";
        progressBarLabelInference.textContent = "Text encoded · " + inferenceProgress.toFixed(2) + "%";

        Utils.log('[Session Run] Beginning UNet loop execution for 25 iterations');

        let latentSpace = new Uint16Array(latentWidth * latentHeight * unetChannelCount);
        generateNoise(/*inout*/ latentSpace, seed);
        // Duplicate the input data, once for each batch (only supports unetBatch == 2).
        latentSpace = new Uint16Array([...latentSpace, ...latentSpace]);

        const latentsTensor = Utils.generateTensorFromBytes(
            'float16',
            [unetBatch, unetChannelCount, latentHeight, latentWidth],
            latentSpace);

        const halfLatentElementCount = latentsTensor.size / 2; // Given [2, 4, 64, 64], we want only the first batch.
        let latents = await latentsTensor.getData();
        let halfLatents = latents.subarray(0, halfLatentElementCount); // First batch only.
        prescaleLatentSpace(/*inout*/ halfLatents, defaultSigmas[0]);

        const unetInputs = {
            'encoder_hidden_states': Utils.generateTensorFromBytes('float16',
                [unetBatch, textEmbeddingSequenceLength, textEmbeddingSequenceWidth],
                textEncoderOutputs['last_hidden_state'].data),
        };

        const startUnet = performance.now();
        // Repeat unet detection and denosing until convergence (typically 25 iterations).
        for (var i = 0; i < unetIterationCount; ++i) {
            // Update time step.
            let startUnetIteration = performance.now();
            const timeStepValue = BigInt(Math.round(defaultTimeSteps[i])); // Round, because this ridiculous language throws an exception otherwise.
            unetInputs['timestep'] = Utils.generateTensorFillValue('int64', [unetBatch], timeStepValue);

            // Prescale the latent values.
            // Copy first batch to second batch, duplicating latents for positive and negative prompts.
            let nextLatents = latents.slice(0);
            let halfNextLatents = nextLatents.subarray(0, halfLatentElementCount);
            scaleLatentSpaceForPrediction(/*inout*/ halfNextLatents, i);
            nextLatents.copyWithin(halfLatentElementCount, 0, halfLatentElementCount); // Copy lower half to upper half.

            unetInputs['sample'] = Utils.generateTensorFromBytes('float16', [unetBatch, unetChannelCount, latentHeight, latentWidth], nextLatents);
            const unetOutputs = await unetModelSession.run(unetInputs);

            let predictedNoise = new Uint16Array(unetOutputs['out_sample'].cpuData.buffer);
            denoiseLatentSpace(/*inout*/ latents, i, predictedNoise);

            let time = (performance.now() - startUnetIteration).toFixed(2);
            performanceData.sessionrun.unet.push(time);
            // Utils.log(`UNet loop ${i + 1} execution time: ${time}ms`);

            inferenceProgress += 3.8;
            progressBarInnerInference.style.width = inferenceProgress + "%";
            progressBarLabelInference.textContent = `UNet iteration ${i + 1} completed · ${inferenceProgress.toFixed(2)}%`;
        }

        let unetExecutionTime = (performance.now() - startUnet).toFixed(2);
        performanceData.sessionrun.unettotal = unetExecutionTime;
        Utils.log(`[Session Run] UNet loop execution time: ${unetExecutionTime}ms`);

        Utils.log('[Session Run] Beginning VAE decode');
        // Decode from latent space.
        applyVaeScalingFactor(/*inout*/ halfLatents);
        let dimensions = latentsTensor.dims.slice(0);
        dimensions[0] = 1; // Set batch size to 1, ignore the 2nd batch for the negative prediction.

        const startVaeDecoder = performance.now();
        const vaeDecoderInputs = {
            'latent_sample': Utils.generateTensorFromBytes('float16', dimensions, halfLatents.slice(0)),
        };
        const decodedOutputs = await vaeDecoderModelSession.run(vaeDecoderInputs);
        let vaeDecoderExecutionTime = (performance.now() - startVaeDecoder).toFixed(2);
        Utils.log(`[Session Run] VAE decode execution time: ${vaeDecoderExecutionTime}ms`);
        performanceData.sessionrun.vaedecoder = vaeDecoderExecutionTime;

        inferenceProgress += 4;
        progressBarInnerInference.style.width = inferenceProgress + "%";
        progressBarLabelInference.textContent = "VAE decoded · " + inferenceProgress.toFixed(2) + "%";

        return decodedOutputs['sample'];
    }

    async function executeStableDiffusionAndDisplayOutput() {
        try {

            error.removeAttribute("class");
            error.innerHTML = '';
            displayEmptyCanvasPlaceholder();

            const executionStartTime = performance.now();
            let rgbPlanarPixels = await executeStableDiffusion();
            const executionTime = performance.now() - executionStartTime;
            performanceData.sessionrun.total = executionTime.toFixed(2);
            Utils.log(`[Total] Total execution time: ${(executionTime / 1000).toFixed(2)}s`);
            console.log(performanceData);
            displayPlanarRGB(await rgbPlanarPixels.getData());
        }
        catch (e) {
            error.setAttribute("class", "error");
            error.innerHTML = e.message;
            console.log('Exception: ', e);
            Utils.appendStatus('Exception: ' + e);
        }
    }

    async function generateNextImage() {
        await executeStableDiffusionAndDisplayOutput();
        // seed++;
        console.log(seed);
        startButton.disabled = false;

        if (performanceData.sessionrun.total) {
            textEncoderLoad.innerHTML = performanceData.loadtime.textencoder
            textEncoderFetch.innerHTML = performanceData.modelfetch.textencoder;
            textEncoderCreate.innerHTML = performanceData.sessioncreate.textencoder;
            textEncoderRun.innerHTML = performanceData.sessionrun.textencoder;

            unetLoad.innerHTML = performanceData.loadtime.unet;
            unetFetch.innerHTML = performanceData.modelfetch.unet;
            unetCreate.innerHTML = performanceData.sessioncreate.unet;
            unetRun.innerHTML = performanceData.sessionrun.unet.toString().replaceAll(',', ' ') + '<br/>25 Iterations: ' + performanceData.sessionrun.unettotal;

            vaeDecoderLoad.innerHTML = performanceData.loadtime.vaedecoder;
            vaeDecoderFetch.innerHTML = performanceData.modelfetch.vaedecoder;
            vaeDecoderCreate.innerHTML = performanceData.sessioncreate.vaedecoder;
            vaeDecoderRun.innerHTML = performanceData.sessionrun.vaedecoder;

            totalLoad.innerHTML = performanceData.loadtime.total;
            totalRun.innerHTML = performanceData.sessionrun.total;
        }

        data.setAttribute('class', 'show');
    }

    const executionProvider = Utils.getQueryVariable('provider', 'webnn');
    Utils.log('[Load] Execution Provider: ' + executionProvider);

    const checkWebNN = async () => {
        let status = document.querySelector('#webnnstatus');
        let info = document.querySelector('#info');
        let webnnStatus = await Utils.webNnStatus();

        if (webnnStatus.webnn) {
            status.setAttribute('class', 'green');
            info.innerHTML = 'WebNN supported · 6GB available memory required';
        } else {
            if (webnnStatus.error) {
                status.setAttribute('class', 'red');
                info.innerHTML = 'WebNN not supported: ' + webnnStatus.error;
            } else {
                status.setAttribute('class', 'red');
                info.innerHTML = 'WebNN not supported';
            }
        }

        if (Utils.getQueryValue('provider') && Utils.getQueryValue('provider').toLowerCase().indexOf('webgpu') > -1) {
            status.innerHTML = '';
        }
    };

    const ui = async () => {
        await setupORT();
        if (Utils.getQueryValue('provider') && Utils.getQueryValue('provider').toLowerCase().indexOf('webgpu') > -1) {
            title.innerHTML = 'WebGPU';
        }
        await checkWebNN();
        initializeOnnxRuntime();
        displayEmptyCanvasPlaceholder();
    };

    document.addEventListener('DOMContentLoaded', ui, false);

    const updateSeed = () => {
        userSeed.value = Utils.randomNumber();
        seed = BigInt(userSeed.value);
    }

    changeSeed.addEventListener('click', updateSeed, false);
</script>

</html>